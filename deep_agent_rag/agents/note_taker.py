"""
ç­†è¨˜ç¯€é»
å°‡ç ”ç©¶çµæœè½‰åŒ–ç‚ºç­†è¨˜ï¼Œå­˜å…¥ research_notes ç·©å­˜
"""
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

from .state import DeepAgentState
from ..utils.llm_utils import get_llm


def note_taking_node(state: DeepAgentState, llm=None):
    """ç´€éŒ„ç¯€é»ï¼šå°‡ç ”ç©¶çµæœè½‰åŒ–ç‚ºç­†è¨˜ï¼Œå­˜å…¥ research_notes ç·©å­˜"""
    if llm is None:
        llm = get_llm()
    
    try:
        last_msg = state["messages"][-1]
        completed_count = len(state.get("completed_tasks", []))
        tasks = state.get("tasks", [])
        
        if completed_count >= len(tasks):
            return {}
        
        current_task = tasks[completed_count]
        
        # ä½¿ç”¨ LLM æ‘˜è¦ç ”ç©¶çµæœï¼Œæå–é—œéµè³‡è¨Š
        try:
            summary_prompt = ChatPromptTemplate.from_template(
                "è«‹å°‡ä»¥ä¸‹ç ”ç©¶çµæœæ‘˜è¦ç‚º3-5å€‹é—œéµè¦é»ï¼š\n\n{content}\n\n"
                "è«‹ä»¥ç°¡æ½”çš„æ¢åˆ—å¼å‘ˆç¾ã€‚"
            )
            chain = summary_prompt | llm | StrOutputParser()
            summary = chain.invoke({"content": last_msg.content})
        except:
            # å¦‚æœæ‘˜è¦å¤±æ•—ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å…§å®¹
            summary = last_msg.content[:500] + "..." if len(last_msg.content) > 500 else last_msg.content
        
        note = f"ã€ä»»å‹™ {completed_count + 1}: {current_task}ã€‘\n{summary}\n"
        print(f"   ğŸ“Œ [NoteTaker] å·²ç´€éŒ„ä»»å‹™ {completed_count + 1} çš„ç ”ç©¶ç­†è¨˜ã€‚")
        
        # æ³¨æ„ï¼šç”±æ–¼ä½¿ç”¨äº† operator.addï¼Œé€™è£¡è¿”å›çš„åˆ—è¡¨æœƒè¢«è¿½åŠ åˆ°ç¾æœ‰åˆ—è¡¨
        return {
            "research_notes": [note], 
            "completed_tasks": [current_task]
        }
    except Exception as e:
        print(f"   âš ï¸ [NoteTaker] è¨˜éŒ„å¤±æ•—: {e}")
        return {}

