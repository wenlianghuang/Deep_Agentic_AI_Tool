"""
Simple Chatbot Interface
ç°¡å–®çš„èŠå¤©æ©Ÿå™¨äººç•Œé¢ï¼Œä¸åŒ…å« RAG å’Œ Deep AI Agent åŠŸèƒ½
ç´”ç²¹çš„å°è©±å¼èŠå¤©æ©Ÿå™¨äºº
åŒ…å«å…§å®¹éæ¿¾ Guardrails åŠŸèƒ½ï¼ˆæ··åˆå¼ï¼šé—œéµå­— + èªç¾©éæ¿¾ï¼‰
"""
import gradio as gr
from typing import List, Dict, Any
import time
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.runnables import RunnableLambda
import jieba

from ..utils.llm_utils import get_llm_type, is_using_local_llm, get_llm
from ..guardrails.nemo_manager import get_guardrail_manager


# ==================== Guardrails é…ç½® ====================
# æ•æ„Ÿé—œéµå­—åå–®
BLOCKED_KEYWORDS = [
    "ä¼Šæ–¯è˜­æ•™",
    "é˜¿æ‹‰",
    "å›æ•™å¾’",
    "é»˜ç½•é»˜å¾·",
    "Islam",
    "Allah",
    "Muslim",
    "Muhammad"
]

# æ””æˆªé–€æª»ï¼š5% çš„è©å½™å¯†åº¦
KEYWORD_DENSITY_THRESHOLD = 0.05

# é è¨­æ””æˆªè¨Šæ¯
DEFAULT_BLOCKED_MESSAGE = "æŠ±æ­‰ï¼Œæ‚¨çš„å•é¡ŒåŒ…å«æ•æ„Ÿå…§å®¹ï¼Œç„¡æ³•å›ç­”ã€‚è«‹æ›å€‹è©±é¡Œæˆ–é‡æ–°è¡¨è¿°æ‚¨çš„å•é¡Œã€‚"

# åˆå§‹åŒ– jieba è‡ªå®šç¾©è©å…¸ï¼ˆç¢ºä¿æº–ç¢ºè­˜åˆ¥æ•æ„Ÿè©ï¼‰
def _init_jieba_custom_dict():
    """åˆå§‹åŒ– jieba è‡ªå®šç¾©è©å…¸ï¼Œæ·»åŠ æ•æ„Ÿé—œéµå­—ä»¥æé«˜è­˜åˆ¥æº–ç¢ºåº¦"""
    for keyword in BLOCKED_KEYWORDS:
        jieba.add_word(keyword, freq=10000, tag='sensitive')

# åœ¨æ¨¡çµ„è¼‰å…¥æ™‚åˆå§‹åŒ–
_init_jieba_custom_dict()


def check_content_guardrails(text: str) -> tuple[bool, float]:
    """
    æª¢æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«æ•æ„Ÿå…§å®¹
    
    ä½¿ç”¨ jieba é€²è¡Œæ–·è©ï¼Œè¨ˆç®—æ•æ„Ÿè©å½™å¯†åº¦
    æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡ï¼ˆä¸å€åˆ†å¤§å°å¯«ï¼‰
    
    Args:
        text: è¦æª¢æŸ¥çš„æ–‡æœ¬
    
    Returns:
        tuple[bool, float]: (æ˜¯å¦æ‡‰è©²æ””æˆª, é—œéµå­—å¯†åº¦)
    """
    if not text or not text.strip():
        return False, 0.0
    
    # ä½¿ç”¨ jieba é€²è¡Œæ–·è©
    words = list(jieba.cut(text))
    total_words = len(words)
    
    if total_words == 0:
        return False, 0.0
    
    # å»ºç«‹å°å¯«æ•æ„Ÿè©é›†åˆä»¥ä¾¿å¿«é€Ÿæ¯”å°
    blocked_keywords_lower = {k.lower() for k in BLOCKED_KEYWORDS}
    
    # è¨ˆç®—æ•æ„Ÿè©æ•¸é‡
    sensitive_word_count = 0
    for word in words:
        # ç§»é™¤ç©ºç™½ä¸¦è½‰ç‚ºå°å¯«é€²è¡Œæ¯”å°
        clean_word = word.strip().lower()
        if clean_word and clean_word in blocked_keywords_lower:
            sensitive_word_count += 1
    
    # è¨ˆç®—é—œéµå­—å¯†åº¦
    keyword_density = sensitive_word_count / total_words
    
    # åˆ¤æ–·æ˜¯å¦è¶…éé–€æª»
    should_block = keyword_density >= KEYWORD_DENSITY_THRESHOLD
    
    return should_block, keyword_density


def guardrail_filter(response: str) -> str:
    """
    Guardrail éæ¿¾å‡½æ•¸ - ç”¨æ–¼ LangChain RunnableLambda
    
    Args:
        response: LLM çš„å›æ‡‰æ–‡æœ¬
    
    Returns:
        str: éæ¿¾å¾Œçš„æ–‡æœ¬ï¼ˆå¦‚æœè¶…éé–€æª»å‰‡è¿”å›é è¨­è¨Šæ¯ï¼‰
    """
    should_block, density = check_content_guardrails(response)
    
    if should_block:
        print(f"ğŸš« Guardrails æ””æˆªï¼šé—œéµå­—å¯†åº¦ {density:.2%} è¶…éé–€æª» {KEYWORD_DENSITY_THRESHOLD:.2%}")
        return DEFAULT_BLOCKED_MESSAGE
    else:
        print(f"ğŸŸ¢ Guardrails é€šéï¼šé—œéµå­—å¯†åº¦ {density:.2%} ä½æ–¼é–€æª» {KEYWORD_DENSITY_THRESHOLD:.2%}")
        
    return response


# å‰µå»º LangChain RunnableLambdaï¼ˆç”¨æ–¼ä¸²æ¥åœ¨ Chain æœ«ç«¯ï¼‰
guardrail_runnable = RunnableLambda(guardrail_filter)


def chat_with_llm_streaming(
    message: str,
    history: List[Dict[str, str]],
    system_prompt: str = "ä½ æ˜¯ä¸€å€‹æœ‰å¹«åŠ©çš„AIåŠ©æ‰‹ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”å•é¡Œã€‚",
    enable_guardrails: bool = True
):
    """
    èˆ‡ LLM é€²è¡Œæµå¼å°è©±ï¼ˆé€å­—é¡¯ç¤ºï¼‰
    æ•´åˆæ··åˆå¼ Guardrailsï¼ˆé—œéµå­— + èªç¾©éæ¿¾ï¼‰
    
    Args:
        message: ç”¨æˆ¶è¼¸å…¥çš„æ¶ˆæ¯
        history: å°è©±æ­·å² (å­—å…¸æ ¼å¼ï¼š[{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}, ...])
        system_prompt: ç³»çµ±æç¤ºè©
        enable_guardrails: æ˜¯å¦å•Ÿç”¨ Guardrails å…§å®¹éæ¿¾
    
    Yields:
        List[Dict[str, str]]: æ›´æ–°ä¸­çš„æ­·å²è¨˜éŒ„
    """
    if not message or not message.strip():
        yield history
        return
    
    # ==================== ç«‹å³é¡¯ç¤ºç”¨æˆ¶æ¶ˆæ¯ ====================
    # å…ˆå°‡ç”¨æˆ¶æ¶ˆæ¯æ·»åŠ åˆ°æ­·å²ä¸¦ç«‹å³é¡¯ç¤º
    new_history = history + [{"role": "user", "content": message}]
    yield new_history
    
    try:
        # ==================== è¼¸å…¥éæ¿¾æª¢æŸ¥ ====================
        # æ ¹æ“š checkbox ç‹€æ…‹æ±ºå®šæ˜¯å¦ä½¿ç”¨ Guardrails
        if enable_guardrails:
            guardrail_mgr = get_guardrail_manager()
            should_block_input, blocked_message = guardrail_mgr.check_input(message)
            
            if should_block_input:
                # è¼¸å…¥è¢«é˜»æ“‹ï¼Œé€å­—é¡¯ç¤ºé˜»æ“‹è¨Šæ¯
                print(f"ğŸš« è¼¸å…¥è¢«é˜»æ“‹")
                new_history.append({"role": "assistant", "content": ""})
                
                # æŒ‰å­—ç¬¦é€æ­¥é¡¯ç¤ºé˜»æ“‹è¨Šæ¯ï¼ˆå‰µé€ æ‰“å­—æ•ˆæœï¼‰
                for i in range(len(blocked_message)):
                    new_history[-1] = {"role": "assistant", "content": blocked_message[:i+1]}
                    yield new_history
                    time.sleep(0.01)  # 10ms å»¶é²
                
                # ç¢ºä¿å®Œæ•´é¡¯ç¤º
                new_history[-1] = {"role": "assistant", "content": blocked_message}
                yield new_history
                return
        
        # ç²å– LLM
        llm = get_llm()
        
        # æ§‹å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [SystemMessage(content=system_prompt)]
        
        # æ·»åŠ å°è©±æ­·å²
        for msg in history:
            if msg.get("role") == "user":
                messages.append(HumanMessage(content=msg["content"]))
            elif msg.get("role") == "assistant":
                messages.append(AIMessage(content=msg["content"]))
        
        # æ·»åŠ ç•¶å‰ç”¨æˆ¶æ¶ˆæ¯
        messages.append(HumanMessage(content=message))
        
        # æ·»åŠ ç©ºçš„åŠ©æ‰‹å›æ‡‰ï¼ˆå°‡é€æ­¥å¡«å……ï¼‰
        new_history.append({"role": "assistant", "content": ""})
        full_response = ""
        
        # ä½¿ç”¨æµå¼èª¿ç”¨ç²å–å›æ‡‰
        for chunk in llm.stream(messages):
            # ç²å–å…§å®¹ (chunk å¯èƒ½æ˜¯ BaseMessageChunk)
            content = chunk.content if hasattr(chunk, "content") else str(chunk)
            
            # æŒ‰å­—ç¬¦å¹³æ»‘é¡¯ç¤ºå…§å®¹ï¼ˆå¢åŠ ä¸€é»æ‰“å­—æ„Ÿï¼‰
            for char in content:
                full_response += char
                new_history[-1] = {"role": "assistant", "content": full_response}
                yield new_history
                # å¦‚æœæ˜¯é«˜é€Ÿæ¨¡å‹ï¼Œç¨å¾®å»¶é²ä¸€é»è®“è¦–è¦ºæ›´å¹³æ»‘
                time.sleep(0.005)
            
            # ==================== è¼¸å‡ºéæ¿¾å³æ™‚æª¢æŸ¥ (å¿«é€Ÿå±¤) ====================
            if enable_guardrails:
                # é€²è¡Œå¿«é€Ÿçš„é—œéµå­—å¯†åº¦æª¢æŸ¥ï¼Œé¿å…ç­‰åˆ°ç”Ÿæˆå®Œæ‰ç™¼ç¾
                should_block_fast, _ = check_content_guardrails(full_response)
                if should_block_fast:
                    print(f"ğŸš« è¼¸å‡ºå› é—œéµå­—å¯†åº¦è¢«å³æ™‚é˜»æ“‹")
                    # æ¸…ç©ºç•¶å‰å…§å®¹ï¼Œæº–å‚™é€å­—é¡¯ç¤ºé˜»æ“‹è¨Šæ¯
                    new_history[-1] = {"role": "assistant", "content": ""}
                    yield new_history
                    
                    # é€å­—é¡¯ç¤ºé˜»æ“‹è¨Šæ¯
                    for i in range(len(DEFAULT_BLOCKED_MESSAGE)):
                        new_history[-1] = {"role": "assistant", "content": DEFAULT_BLOCKED_MESSAGE[:i+1]}
                        yield new_history
                        time.sleep(0.01)
                    
                    # ç¢ºä¿å®Œæ•´é¡¯ç¤º
                    new_history[-1] = {"role": "assistant", "content": DEFAULT_BLOCKED_MESSAGE}
                    yield new_history
                    return
        
        # ==================== æœ€çµ‚è¼¸å‡ºéæ¿¾æª¢æŸ¥ (å«èªç¾©) ====================
        # æ ¹æ“š checkbox ç‹€æ…‹æ±ºå®šæ˜¯å¦ä½¿ç”¨ Guardrails
        if enable_guardrails:
            guardrail_mgr = get_guardrail_manager()
            # é€²è¡Œå®Œæ•´çš„æª¢æŸ¥ï¼ˆåŒ…å«å¯èƒ½è¼ƒæ…¢çš„èªç¾©éæ¿¾ï¼‰
            should_block_output, filtered_response = guardrail_mgr.check_output(full_response)
            
            if should_block_output:
                print(f"ğŸš« è¼¸å‡ºè¢«æœ€çµ‚èªç¾©éæ¿¾é˜»æ“‹")
                # æ¸…ç©ºç•¶å‰å…§å®¹ï¼Œæº–å‚™é€å­—é¡¯ç¤ºéæ¿¾å¾Œçš„è¨Šæ¯
                new_history[-1] = {"role": "assistant", "content": ""}
                yield new_history
                
                # é€å­—é¡¯ç¤ºéæ¿¾å¾Œçš„è¨Šæ¯ï¼ˆä¾‹å¦‚è‡ªè¨‚çš„ä¸»é¡Œæ””æˆªè¨Šæ¯ï¼‰
                for i in range(len(filtered_response)):
                    new_history[-1] = {"role": "assistant", "content": filtered_response[:i+1]}
                    yield new_history
                    time.sleep(0.01)
                
                # ç¢ºä¿å®Œæ•´é¡¯ç¤º
                new_history[-1] = {"role": "assistant", "content": filtered_response}
                yield new_history
            else:
                # ç¢ºä¿æœ€çµ‚é¡¯ç¤ºçš„æ˜¯å®Œæ•´çš„å›æ‡‰
                new_history[-1] = {"role": "assistant", "content": full_response}
                yield new_history
        else:
            # ç¢ºä¿å®Œæ•´é¡¯ç¤º
            new_history[-1] = {"role": "assistant", "content": full_response}
            yield new_history
    
    except Exception as e:
        error_msg = f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
        print(f"èŠå¤©éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        
        # æ·»åŠ éŒ¯èª¤å›æ‡‰åˆ°å·²é¡¯ç¤ºç”¨æˆ¶æ¶ˆæ¯çš„æ­·å²
        new_history.append({"role": "assistant", "content": error_msg})
        yield new_history


def get_llm_status() -> str:
    """ç²å–ç•¶å‰ LLM ç‹€æ…‹ä¿¡æ¯"""
    if is_using_local_llm():
        return "âš ï¸ **ç•¶å‰ä½¿ç”¨ï¼šæœ¬åœ° MLX æ¨¡å‹ (Qwen2.5)**\n\næœ¬åœ°æ¨¡å‹è™•ç†é€Ÿåº¦å¯èƒ½è¼ƒæ…¢ï¼Œè«‹è€å¿ƒç­‰å¾…ã€‚"
    else:
        llm_type = get_llm_type()
        if llm_type == "groq":
            return "âœ… **ç•¶å‰ä½¿ç”¨ï¼šGroq API (é«˜é€Ÿé›²ç«¯æ¨¡å‹)**"
        else:
            return "â„¹ï¸ **ç•¶å‰ä½¿ç”¨ï¼šæœ¬åœ° MLX æ¨¡å‹ (Qwen2.5)**"


def get_guardrails_status() -> str:
    """ç²å–ç•¶å‰ Guardrails ç‹€æ…‹ä¿¡æ¯"""
    try:
        guardrail_mgr = get_guardrail_manager()
        status = guardrail_mgr.get_status()
        topics = guardrail_mgr.get_topics_info()
        
        enabled = status.get("enabled", {})
        keyword_filter = status.get("keyword_filter", {})
        semantic_filter = status.get("semantic_filter", {})
        
        status_text = "# ğŸ›¡ï¸ Guardrails ç‹€æ…‹\n\n"
        status_text += "## æ··åˆéæ¿¾ç­–ç•¥\n\n"
        
        # é—œéµå­—éæ¿¾ç‹€æ…‹
        if enabled.get("keyword_filter", False):
            status_text += f"âœ… **é—œéµå­—éæ¿¾**ï¼šå·²å•Ÿç”¨\n"
            status_text += f"   - å¯†åº¦é–€æª»ï¼š{keyword_filter.get('threshold', 0.05):.1%}\n"
            status_text += f"   - é—œéµå­—æ•¸é‡ï¼š{keyword_filter.get('keywords_count', 0)} å€‹\n\n"
        else:
            status_text += "âŒ **é—œéµå­—éæ¿¾**ï¼šå·²åœç”¨\n\n"
        
        # èªç¾©éæ¿¾ç‹€æ…‹
        if enabled.get("semantic_filter", False):
            if semantic_filter.get("initialized", False):
                status_text += f"âœ… **èªç¾©ä¸»é¡Œéæ¿¾**ï¼šå·²å•Ÿç”¨\n"
                status_text += f"   - ç›¸ä¼¼åº¦é–€æª»ï¼š{semantic_filter.get('threshold', 0.75):.1%}\n"
                status_text += f"   - ä¸»é¡Œæ•¸é‡ï¼š{semantic_filter.get('topics_count', 0)} å€‹\n\n"
                
                if topics:
                    status_text += "   **ä¸»é¡Œåˆ—è¡¨**ï¼š\n"
                    for topic in topics:
                        status_text += f"   - {topic['display_name']} ({topic['examples_count']} å€‹ç¯„ä¾‹)\n"
            else:
                status_text += "âš ï¸ **èªç¾©ä¸»é¡Œéæ¿¾**ï¼šå•Ÿç”¨ä¸­ï¼ˆæ¨¡å‹æœªåˆå§‹åŒ–ï¼‰\n\n"
        else:
            status_text += "âŒ **èªç¾©ä¸»é¡Œéæ¿¾**ï¼šå·²åœç”¨\n\n"
        
        # é˜²è­·æ–¹å‘
        status_text += "\n## é˜²è­·æ–¹å‘\n\n"
        if enabled.get("input_rails", False):
            status_text += "âœ… **è¼¸å…¥éæ¿¾**ï¼šå·²å•Ÿç”¨ï¼ˆé˜»æ“‹æ•æ„Ÿå•é¡Œï¼‰\n"
        else:
            status_text += "âŒ **è¼¸å…¥éæ¿¾**ï¼šå·²åœç”¨\n"
        
        if enabled.get("output_rails", False):
            status_text += "âœ… **è¼¸å‡ºéæ¿¾**ï¼šå·²å•Ÿç”¨ï¼ˆéæ¿¾å›æ‡‰å…§å®¹ï¼‰\n"
        else:
            status_text += "âŒ **è¼¸å‡ºéæ¿¾**ï¼šå·²åœç”¨\n"
        
        return status_text
    
    except Exception as e:
        return f"âš ï¸ ç„¡æ³•ç²å– Guardrails ç‹€æ…‹ï¼š{str(e)}"


def create_simple_chatbot_interface():
    """
    å‰µå»ºç°¡å–®èŠå¤©æ©Ÿå™¨äººç•Œé¢
    ç´”ç²¹çš„å°è©±å¼èŠå¤©ï¼Œä¸åŒ…å« RAG æˆ–å…¶ä»–è¤‡é›œåŠŸèƒ½
    """
    with gr.Blocks(title="Simple Chatbot") as demo:
        # æ¨™é¡Œ
        gr.Markdown(
            """
            <div style="text-align: center; padding: 20px;">
                <h1>ğŸ’¬ Simple Chatbot</h1>
                <p style="font-size: 16px; color: #666;">
                    ç°¡å–®çš„å°è©±å¼èŠå¤©æ©Ÿå™¨äºº - ç´”ç²¹çš„ AI å°è©±é«”é©—
                </p>
                <p style="font-size: 14px; color: #888;">
                    ä¸åŒ…å« RAGã€Deep AI Agent ç­‰è¤‡é›œåŠŸèƒ½ï¼Œåªå°ˆæ³¨æ–¼è‡ªç„¶å°è©±
                </p>
            </div>
            """
        )
        
        # LLM ç‹€æ…‹é¡¯ç¤º
        llm_status = gr.Markdown(
            value=get_llm_status(),
            elem_classes=["warning-box"]
        )
        
        # Guardrails å•Ÿç”¨é–‹é—œ
        with gr.Row():
            enable_guardrails_checkbox = gr.Checkbox(
                label="ğŸ›¡ï¸ å•Ÿç”¨ Guardrails å…§å®¹éæ¿¾",
                value=True,
                info="å•Ÿç”¨å¾Œå°‡æª¢æŸ¥è¼¸å…¥å’Œè¼¸å‡ºå…§å®¹ï¼Œé˜»æ“‹æ•æ„Ÿè©±é¡Œ"
            )
        
        # ç³»çµ±æç¤ºè©è¨­å®šï¼ˆå¯é¸ï¼‰
        with gr.Accordion("âš™ï¸ é€²éšè¨­å®š", open=False):
            system_prompt = gr.Textbox(
                label="ç³»çµ±æç¤ºè© (System Prompt)",
                value="ä½ æ˜¯ä¸€å€‹æœ‰å¹«åŠ©çš„AIåŠ©æ‰‹ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”å•é¡Œã€‚",
                lines=3,
                placeholder="è¨­å®š AI çš„è§’è‰²å’Œè¡Œç‚ºæ–¹å¼..."
            )
            
            gr.Markdown(
                """
                **æç¤ºè©ç¯„ä¾‹ï¼š**
                - å°ˆæ¥­åŠ©æ‰‹ï¼šã€Œä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æŠ€è¡“é¡§å•ï¼Œæ“…é•·è§£é‡‹è¤‡é›œçš„æŠ€è¡“æ¦‚å¿µã€‚ã€
                - å‰µæ„å¯«ä½œï¼šã€Œä½ æ˜¯ä¸€ä½å¯Œæœ‰å‰µæ„çš„ä½œå®¶ï¼Œæ“…é•·å¯«ä½œæ•…äº‹å’Œè©©æ­Œã€‚ã€
                - å­¸ç¿’è¼”å°ï¼šã€Œä½ æ˜¯ä¸€ä½è€å¿ƒçš„è€å¸«ï¼Œæ“…é•·ç”¨ç°¡å–®çš„æ–¹å¼è§£é‡‹è¤‡é›œçš„æ¦‚å¿µã€‚ã€
                """
            )
        
        # Guardrails è¨­å®šé¡¯ç¤º
        with gr.Accordion("ğŸ›¡ï¸ å…§å®¹éæ¿¾ Guardrailsï¼ˆæ··åˆç­–ç•¥ï¼‰", open=False):
            guardrails_status_md = gr.Markdown(
                value=get_guardrails_status()
            )
            
            with gr.Row():
                refresh_guardrails_btn = gr.Button("ğŸ”„ æ›´æ–° Guardrails ç‹€æ…‹", variant="secondary", size="sm")
            
            gr.Markdown(
                """
                ---
                
                ## æ··åˆç­–ç•¥èªªæ˜
                
                æœ¬ç³»çµ±æ¡ç”¨**é›™å±¤éæ¿¾**ç­–ç•¥ï¼Œå— NeMo Guardrails å•Ÿç™¼ï¼š
                
                ### ç¬¬ä¸€å±¤ï¼šé—œéµå­—å¯†åº¦æª¢æŸ¥ï¼ˆå¿«é€Ÿå±¤ï¼‰
                - âš¡ é€Ÿåº¦ï¼š< 1ms
                - ğŸ” ä½¿ç”¨ `jieba` é€²è¡Œä¸­è‹±æ–‡æ–·è©
                - ğŸ“Š è¨ˆç®—æ•æ„Ÿè©å¯†åº¦ï¼ˆæ•æ„Ÿè©æ•¸ / ç¸½è©æ•¸ï¼‰
                - ğŸ¯ é©ç”¨æ–¼ï¼šæ˜ç¢ºçš„é—œéµå­—åŒ¹é…
                
                ### ç¬¬äºŒå±¤ï¼šèªç¾©ä¸»é¡Œéæ¿¾ï¼ˆæ·±åº¦å±¤ï¼‰
                - ğŸ¤– ä½¿ç”¨ Sentence Transformers èªç¾©ç†è§£
                - ğŸ­ å¯åµæ¸¬æ”¹å¯«ã€éš±å–»ç­‰è¤‡é›œè¡¨é”
                - ğŸ“ åŸºæ–¼ä¸»é¡Œç¯„ä¾‹é€²è¡Œç›¸ä¼¼åº¦åŒ¹é…
                - ğŸ¯ é©ç”¨æ–¼ï¼šä¸»é¡Œå±¤ç´šçš„å…§å®¹æ§åˆ¶
                
                ### é›™å‘é˜²è­·
                - ğŸ”’ **è¼¸å…¥éæ¿¾**ï¼šé˜»æ“‹æ•æ„Ÿå•é¡Œ
                - ğŸ›¡ï¸ **è¼¸å‡ºéæ¿¾**ï¼šç¢ºä¿å›æ‡‰å®‰å…¨
                
                â„¹ï¸ é…ç½®æ–‡ä»¶ä½æ–¼ï¼š`deep_agent_rag/guardrails/config/`
                """
            )
        
        # èŠå¤©ç•Œé¢ï¼ˆGradio 5.x+ é»˜èªä½¿ç”¨å­—å…¸æ ¼å¼ï¼‰
        chatbot = gr.Chatbot(
            label="å°è©±è¨˜éŒ„",
            height=500,
            show_label=True
        )
        
        # è¼¸å…¥å€åŸŸ
        msg = gr.Textbox(
            label="è¨Šæ¯",
            placeholder="åœ¨é€™è£¡è¼¸å…¥æ‚¨çš„è¨Šæ¯...",
            lines=2,
            show_label=False
        )
        
        # æ§åˆ¶æŒ‰éˆ•
        with gr.Row():
            submit_btn = gr.Button("ğŸ“¤ ç™¼é€", variant="primary")
            clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤å°è©±", variant="secondary")
            refresh_status_btn = gr.Button("ğŸ”„ æ›´æ–°ç‹€æ…‹", variant="secondary")
        
        # ç¤ºä¾‹å•é¡Œ
        gr.Examples(
            examples=[
                "ä½ å¥½ï¼è«‹ä»‹ç´¹ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
                "è«‹å¹«æˆ‘è§£é‡‹ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
                "èƒ½çµ¦æˆ‘ä¸€äº›å­¸ç¿’ Python çš„å»ºè­°å—ï¼Ÿ",
                "è«‹ç”¨ç°¡å–®çš„æ–¹å¼è§£é‡‹é‡å­è¨ˆç®—ã€‚",
                "å¯«ä¸€é¦–é—œæ–¼æ˜¥å¤©çš„çŸ­è©©ã€‚"
            ],
            inputs=msg,
            label="ğŸ’¡ å¿«é€Ÿè©¦ç”¨ç¯„ä¾‹"
        )
        
        # äº‹ä»¶ç¶å®š
        def clear_chat():
            """æ¸…é™¤å°è©±"""
            return [], ""
        
        def refresh_status():
            """æ›´æ–° LLM ç‹€æ…‹"""
            return get_llm_status()
        
        def refresh_guardrails_status():
            """æ›´æ–° Guardrails ç‹€æ…‹"""
            return get_guardrails_status()
        
        # ç™¼é€æ¶ˆæ¯äº‹ä»¶
        msg.submit(
            fn=chat_with_llm_streaming,
            inputs=[msg, chatbot, system_prompt, enable_guardrails_checkbox],
            outputs=[chatbot],
            queue=True
        ).then(
            fn=lambda: "",
            outputs=[msg],
            queue=False
        )
        
        submit_btn.click(
            fn=chat_with_llm_streaming,
            inputs=[msg, chatbot, system_prompt, enable_guardrails_checkbox],
            outputs=[chatbot],
            queue=True
        ).then(
            fn=lambda: "",
            outputs=[msg],
            queue=False
        )
        
        clear_btn.click(
            fn=clear_chat,
            outputs=[chatbot, msg],
            queue=False
        )
        
        refresh_status_btn.click(
            fn=refresh_status,
            outputs=[llm_status],
            queue=False
        )
        
        refresh_guardrails_btn.click(
            fn=refresh_guardrails_status,
            outputs=[guardrails_status_md],
            queue=False
        )
        
        # é è…³
        gr.Markdown(
            """
            ---
            ### ğŸ“ ä½¿ç”¨èªªæ˜
            
            1. **é–‹å§‹å°è©±**ï¼šåœ¨è¼¸å…¥æ¡†ä¸­è¼¸å…¥è¨Šæ¯ï¼Œé»æ“Šã€Œç™¼é€ã€æˆ–æŒ‰ Enter
            2. **ç³»çµ±æç¤ºè©**ï¼šå±•é–‹ã€Œé€²éšè¨­å®šã€å¯è‡ªè¨‚ AI çš„è§’è‰²å’Œè¡Œç‚º
            3. **æ¸…é™¤å°è©±**ï¼šé»æ“Šã€Œæ¸…é™¤å°è©±ã€å¯é‡æ–°é–‹å§‹
            4. **å¿«é€Ÿè©¦ç”¨**ï¼šé»æ“Šä¸‹æ–¹çš„ç¯„ä¾‹å•é¡Œå¿«é€Ÿæ¸¬è©¦
            
            **ç‰¹è‰²åŠŸèƒ½ï¼š**
            - ğŸ¯ ç´”ç²¹çš„å°è©±é«”é©—ï¼Œç„¡è¤‡é›œåŠŸèƒ½
            - ğŸ’« æµå¼è¼¸å‡ºï¼Œé€å­—é¡¯ç¤ºå›æ‡‰
            - ğŸ”§ å¯è‡ªè¨‚ç³»çµ±æç¤ºè©
            - ğŸ“ ä¿ç•™å®Œæ•´å°è©±æ­·å²
            - ğŸš€ æ”¯æŒæœ¬åœ°æ¨¡å‹å’Œé›²ç«¯ API
            - ğŸ›¡ï¸ æ··åˆå¼ Guardrails å…§å®¹éæ¿¾ï¼ˆé—œéµå­— + èªç¾©é›™å±¤é˜²è­·ï¼‰
            - ğŸ”’ é›™å‘éæ¿¾ï¼ˆè¼¸å…¥é˜»æ“‹ + è¼¸å‡ºéæ¿¾ï¼‰
            """
        )
    
    return demo


# å¦‚æœç›´æ¥åŸ·è¡Œæ­¤æ–‡ä»¶ï¼Œå•Ÿå‹•ç•Œé¢
if __name__ == "__main__":
    demo = create_simple_chatbot_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7861,
        share=False,
        show_error=True
    )
