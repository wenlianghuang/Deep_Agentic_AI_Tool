"""
åœ–ç‰‡åˆ†æç•Œé¢æ¨¡çµ„
æä¾›ç¨ç«‹çš„åœ–ç‰‡åˆ†æ UI
"""
import gradio as gr
import os
import tempfile
from typing import Tuple, Optional

from ..tools.image_analysis_tool import get_multimodal_llm
from ..graph.image_analysis_graph import build_image_analysis_graph
from ..config import (
    OPENAI_API_KEY,
    GOOGLE_GEMINI_API_KEY,
    ANTHROPIC_API_KEY,
    USE_OLLAMA_VISION,
    OLLAMA_VISION_MODEL,
    MAX_REFLECTION_ITERATION,
)


def get_available_providers() -> str:
    """
    ç²å–ç•¶å‰å¯ç”¨çš„å¤šæ¨¡æ…‹ API æä¾›å•†ä¿¡æ¯
    
    Returns:
        æä¾›å•†ä¿¡æ¯å­—ç¬¦ä¸²
    """
    providers = []
    
    if OPENAI_API_KEY:
        providers.append("âœ… OpenAI GPT-4 Vision")
    else:
        providers.append("âŒ OpenAI GPT-4 Vision (æœªé…ç½®)")
    
    if GOOGLE_GEMINI_API_KEY:
        providers.append("âœ… Google Gemini")
    else:
        providers.append("âŒ Google Gemini (æœªé…ç½®)")
    
    if ANTHROPIC_API_KEY:
        providers.append("âœ… Anthropic Claude")
    else:
        providers.append("âŒ Anthropic Claude (æœªé…ç½®)")
    
    if USE_OLLAMA_VISION:
        providers.append("âœ… Ollama LLaVA (æœ¬åœ°)")
    else:
        providers.append("âŒ Ollama LLaVA (æœªå•Ÿç”¨)")
    
    return "\n".join(providers)


def analyze_image_ui(
    image: Optional[gr.File],
    question: str,
    progress: Optional[gr.Progress] = None
) -> Tuple[str, str, str]:
    """
    åˆ†æåœ–ç‰‡çš„ UI è™•ç†å‡½æ•¸ï¼ˆä½¿ç”¨ LangGraph å·¥ä½œæµï¼ŒåŒ…å«åæ€ï¼‰
    
    Args:
        image: ä¸Šå‚³çš„åœ–ç‰‡æ–‡ä»¶
        question: å¯é¸çš„å•é¡Œ
        progress: Gradio é€²åº¦æ¢ï¼ˆå¯é¸ï¼‰
    
    Returns:
        (åˆ†æçµæœ, åæ€çµæœ, ç‹€æ…‹è¨Šæ¯)
    """
    if image is None:
        return "", "", "âŒ è«‹å…ˆä¸Šå‚³ä¸€å¼µåœ–ç‰‡"
    
    try:
        # ç²å–åœ–ç‰‡æ–‡ä»¶è·¯å¾‘
        if isinstance(image, str):
            image_path = image
        elif hasattr(image, 'name'):
            image_path = image.name
        elif isinstance(image, dict) and 'name' in image:
            image_path = image['name']
        else:
            return "", "", "âŒ ç„¡æ³•è®€å–åœ–ç‰‡æ–‡ä»¶ï¼Œè«‹é‡æ–°ä¸Šå‚³"
        
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not image_path or not os.path.exists(image_path):
            return "", "", f"âŒ åœ–ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}"
        
        # é¡¯ç¤ºç•¶å‰ä½¿ç”¨çš„ API æä¾›å•†
        llm, provider = get_multimodal_llm()
        if llm is None:
            return "", "", provider  # è¿”å›éŒ¯èª¤è¨Šæ¯
        
        status_msg = f"ğŸ”„ æ­£åœ¨ä½¿ç”¨ {provider.upper()} åˆ†æåœ–ç‰‡ï¼ˆåŒ…å« AI åæ€ï¼‰..."
        if progress is not None:
            progress(0.1, desc=status_msg)
        
        # æ§‹å»ºå•é¡Œï¼ˆå¦‚æœæä¾›ï¼‰
        question_text = question.strip() if question else None
        
        # æ§‹å»º LangGraph å·¥ä½œæµ
        graph = build_image_analysis_graph()
        
        # åˆå§‹åŒ–ç‹€æ…‹
        initial_state = {
            "question": question_text,
            "image_path": image_path,
            "analysis_result": "",
            "reflection_result": "",
            "improvement_suggestions": "",
            "needs_revision": False,
            "iteration": 0,
            "messages": []
        }
        
        # åŸ·è¡Œå·¥ä½œæµ
        config = {"configurable": {"thread_id": f"image-analysis-{os.path.basename(image_path)}"}}
        
        final_analysis = ""
        final_reflection = ""
        current_status = status_msg
        final_iteration = 0
        
        if progress is not None:
            progress(0.2, desc="é–‹å§‹åˆ†æåœ–ç‰‡...")
        
        # æµå¼åŸ·è¡Œå·¥ä½œæµ
        for event in graph.stream(initial_state, config, stream_mode="updates"):
            for node_name, node_state in event.items():
                iteration = node_state.get("iteration", 0)
                final_iteration = max(final_iteration, iteration)
                
                if progress is not None:
                    max_iter = MAX_REFLECTION_ITERATION + 1  # +1 å› ç‚ºåˆå§‹åˆ†æä¹Ÿç®—ä¸€è¼ª
                    progress_val = min(0.2 + (iteration / max_iter) * 0.7, 0.9)
                    
                if node_name == "analyze":
                    current_status = f"ğŸ”„ ç¬¬ {iteration} è¼ªï¼šæ­£åœ¨åˆ†æåœ–ç‰‡..."
                    if progress is not None:
                        progress(progress_val, desc=current_status)
                
                elif node_name == "reflection":
                    current_status = f"ğŸ” ç¬¬ {iteration} è¼ªï¼šæ­£åœ¨åæ€åˆ†æçµæœ..."
                    if "reflection_result" in node_state and node_state["reflection_result"]:
                        final_reflection = node_state["reflection_result"]
                    if progress is not None:
                        progress(progress_val, desc=current_status)
                
                elif node_name == "improvement":
                    current_status = f"âœ¨ ç¬¬ {iteration} è¼ªï¼šæ­£åœ¨ç”Ÿæˆæ”¹é€²ç‰ˆæœ¬..."
                    if progress is not None:
                        progress(progress_val, desc=current_status)
                
                # æ›´æ–°æœ€çµ‚çµæœ
                if "analysis_result" in node_state:
                    final_analysis = node_state["analysis_result"]
                if "reflection_result" in node_state and node_state["reflection_result"]:
                    final_reflection = node_state["reflection_result"]
        
        if progress is not None:
            progress(1.0, desc="åˆ†æå®Œæˆï¼")
        
        # æª¢æŸ¥çµæœæ˜¯å¦ç‚ºéŒ¯èª¤è¨Šæ¯
        if final_analysis.startswith("âŒ"):
            return "", "", final_analysis
        
        # æ§‹å»ºæœ€çµ‚ç‹€æ…‹è¨Šæ¯
        if final_iteration > 1:
            final_status = f"âœ… åˆ†æå®Œæˆï¼ä½¿ç”¨ {provider.upper()} APIï¼ˆç¶“é {final_iteration} è¼ªåˆ†æï¼‰"
        else:
            final_status = f"âœ… åˆ†æå®Œæˆï¼ä½¿ç”¨ {provider.upper()} API"
        
        return final_analysis, final_reflection, final_status
        
    except Exception as e:
        error_msg = f"âŒ åˆ†æåœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
        print(f"åœ–ç‰‡åˆ†æéŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()
        return "", "", error_msg




def _create_image_analysis_interface():
    """å‰µå»ºåœ–ç‰‡åˆ†æç•Œé¢"""
    gr.Markdown(
        """
        ### ğŸ–¼ï¸ æ™ºèƒ½åœ–ç‰‡åˆ†æå·¥å…·
        
        ä½¿ç”¨å¤šæ¨¡æ…‹ AI æ¨¡å‹åˆ†æåœ–ç‰‡å…§å®¹ï¼Œæ”¯æŒå¤šå€‹ API æä¾›å•†è‡ªå‹•åˆ‡æ›ã€‚
        
        **æ”¯æŒçš„åŠŸèƒ½ï¼š**
        - ğŸ“¸ åœ–ç‰‡å…§å®¹è­˜åˆ¥å’Œæè¿°
        - ğŸ” å›ç­”é—œæ–¼åœ–ç‰‡çš„ç‰¹å®šå•é¡Œ
        - ğŸ¨ åˆ†æåœ–ç‰‡é¢¨æ ¼ã€æ§‹åœ–ã€è‰²å½©ç­‰è¦–è¦ºç‰¹å¾µ
        - ğŸ“ è­˜åˆ¥åœ–ç‰‡ä¸­çš„æ–‡å­—ï¼ˆOCRï¼‰
        
        **æ”¯æŒçš„ API æä¾›å•†ï¼š**
        - OpenAI GPT-4 Vision
        - Google Geminiï¼ˆæ¨è–¦ï¼Œå…è²»é¡åº¦è¼ƒé«˜ï¼‰
        - Anthropic Claude
        - Ollama LLaVAï¼ˆæœ¬åœ°ï¼Œå®Œå…¨å…è²»ï¼‰
        
        **ä½¿ç”¨æ–¹å¼ï¼š**
        1. ä¸Šå‚³ä¸€å¼µåœ–ç‰‡ï¼ˆæ”¯æŒ jpg, png, gif, webp ç­‰æ ¼å¼ï¼‰
        2. ï¼ˆå¯é¸ï¼‰è¼¸å…¥ç‰¹å®šå•é¡Œï¼Œä¾‹å¦‚ï¼š"é€™å¼µåœ–ç‰‡ä¸­æœ‰ä»€éº¼ï¼Ÿ"ã€"æè¿°åœ–ç‰‡ä¸­çš„å ´æ™¯"
        3. é»æ“Šã€Œåˆ†æåœ–ç‰‡ã€æŒ‰éˆ•
        4. æŸ¥çœ‹ AI çš„åˆ†æçµæœå’Œåæ€è©•ä¼°
        
        **âœ¨ æ–°åŠŸèƒ½ï¼šAI åæ€è©•ä¼°**
        - ç³»çµ±æœƒè‡ªå‹•è©•ä¼°åˆ†æçµæœçš„è³ªé‡
        - å¦‚æœåˆ†ææœ‰æ”¹é€²ç©ºé–“ï¼Œæœƒè‡ªå‹•ç”Ÿæˆæ”¹é€²ç‰ˆæœ¬
        - æœ€å¤šé€²è¡Œ {MAX_REFLECTION_ITERATION} è¼ªæ”¹é€²ï¼ˆé¿å…å…è²» API é¡åº¦å¿«é€Ÿç”¨å®Œï¼‰
        
        **æç¤ºï¼š** å¦‚æœä¸è¼¸å…¥å•é¡Œï¼Œç³»çµ±æœƒé€²è¡Œé€šç”¨çš„åœ–ç‰‡åˆ†æã€‚
        """
    )
    
    # é¡¯ç¤ºç•¶å‰å¯ç”¨çš„ API æä¾›å•†
    with gr.Accordion("ğŸ“Š ç•¶å‰å¯ç”¨çš„ API æä¾›å•†", open=False):
        providers_display = gr.Markdown(
            value=get_available_providers(),
            elem_classes=["provider-info"]
        )
        
        refresh_providers_btn = gr.Button("ğŸ”„ åˆ·æ–°æä¾›å•†ç‹€æ…‹", variant="secondary", size="sm")
        
        def refresh_providers():
            return get_available_providers()
        
        refresh_providers_btn.click(
            fn=refresh_providers,
            outputs=[providers_display]
        )
    
    with gr.Row():
        with gr.Column(scale=1):
            # åœ–ç‰‡ä¸Šå‚³å€åŸŸ
            image_input = gr.File(
                label="ğŸ“¸ ä¸Šå‚³åœ–ç‰‡",
                file_types=["image"],
                type="filepath"
            )
            
            # åœ–ç‰‡é è¦½
            image_preview = gr.Image(
                label="åœ–ç‰‡é è¦½",
                type="filepath",
                height=300,
                visible=True
            )
            
            # å•é¡Œè¼¸å…¥ï¼ˆå¯é¸ï¼‰
            question_input = gr.Textbox(
                label="â“ å•é¡Œï¼ˆå¯é¸ï¼‰",
                placeholder="ä¾‹å¦‚ï¼šé€™å¼µåœ–ç‰‡ä¸­æœ‰ä»€éº¼ï¼Ÿæè¿°åœ–ç‰‡ä¸­çš„å ´æ™¯ã€‚å¦‚æœä¸å¡«ï¼Œå°‡é€²è¡Œé€šç”¨åˆ†æã€‚",
                lines=3,
                value=""
            )
            
            # æŒ‰éˆ•
            with gr.Row():
                analyze_btn = gr.Button("ğŸ” åˆ†æåœ–ç‰‡", variant="primary", scale=2)
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤", variant="secondary", scale=1)
            
            # ç‹€æ…‹é¡¯ç¤º
            status_display = gr.Textbox(
                label="ğŸ“Š ç‹€æ…‹",
                value="ç­‰å¾…ä¸Šå‚³åœ–ç‰‡...",
                interactive=False,
                lines=2
            )
        
        with gr.Column(scale=1):
            # åˆ†æçµæœé¡¯ç¤º
            result_display = gr.Textbox(
                label="ğŸ“„ åˆ†æçµæœ",
                placeholder="åˆ†æçµæœå°‡é¡¯ç¤ºåœ¨é€™è£¡...",
                lines=12,
                interactive=True  # è¨­ç‚º True ä»¥ä¾¿ç”¨æˆ¶å¯ä»¥è¤‡è£½å…§å®¹
            )
            
            # åæ€çµæœé¡¯ç¤º
            reflection_display = gr.Textbox(
                label="ğŸ” AI åæ€è©•ä¼°",
                placeholder="AI åæ€è©•ä¼°çµæœå°‡é¡¯ç¤ºåœ¨é€™è£¡...",
                lines=8,
                interactive=False,
                visible=True
            )
    
    # æ›´æ–°åœ–ç‰‡é è¦½
    def update_image_preview(image):
        """æ›´æ–°åœ–ç‰‡é è¦½"""
        if image is None:
            return None
        
        # è™•ç†ä¸åŒé¡å‹çš„è¼¸å…¥
        if hasattr(image, 'name'):
            file_path = image.name
        elif isinstance(image, str):
            file_path = image
        elif isinstance(image, dict) and 'name' in image:
            file_path = image['name']
        else:
            return None
        
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if file_path and os.path.exists(file_path):
            return file_path
        return None
    
    image_input.change(
        fn=update_image_preview,
        inputs=[image_input],
        outputs=[image_preview]
    )
    
    # åˆ†ææŒ‰éˆ•äº‹ä»¶
    analyze_btn.click(
        fn=analyze_image_ui,
        inputs=[image_input, question_input],
        outputs=[result_display, reflection_display, status_display],
        show_progress="full"
    )
    
    # æ¸…é™¤æŒ‰éˆ•äº‹ä»¶
    def clear_image_analysis():
        """æ¸…é™¤æ‰€æœ‰è¼¸å…¥å’Œè¼¸å‡º"""
        return None, "", "", "", "ç­‰å¾…ä¸Šå‚³åœ–ç‰‡..."
    
    clear_btn.click(
        fn=clear_image_analysis,
        outputs=[image_input, question_input, result_display, reflection_display, status_display]
    )
    
    # ç¤ºä¾‹å•é¡Œ
    gr.Examples(
        examples=[
            "é€™å¼µåœ–ç‰‡ä¸­æœ‰ä»€éº¼ï¼Ÿ",
            "æè¿°åœ–ç‰‡ä¸­çš„å ´æ™¯å’Œäººç‰©",
            "åœ–ç‰‡ä¸­çš„æ–‡å­—æ˜¯ä»€éº¼ï¼Ÿ",
            "åˆ†æé€™å¼µåœ–ç‰‡çš„é¢¨æ ¼å’Œæ§‹åœ–",
            "é€™å¼µåœ–ç‰‡è¡¨é”äº†ä»€éº¼æƒ…æ„Ÿæˆ–æ„ç¾©ï¼Ÿ"
        ],
        inputs=question_input,
        label="ğŸ’¡ å¿«é€Ÿå•é¡Œç¯„ä¾‹"
    )
    
    # ä½¿ç”¨èªªæ˜
    gr.Markdown(
        """
        ---
        **ğŸ’¡ ä½¿ç”¨æŠ€å·§ï¼š**
        
        1. **é€šç”¨åˆ†æ**ï¼šä¸ä¸Šå‚³å•é¡Œï¼Œè®“ AI è‡ªå‹•åˆ†æåœ–ç‰‡çš„æ‰€æœ‰æ–¹é¢
        2. **ç‰¹å®šå•é¡Œ**ï¼šè¼¸å…¥å…·é«”å•é¡Œï¼Œç²å¾—é‡å°æ€§çš„å›ç­”
        3. **å¤šå¼µåœ–ç‰‡**ï¼šç›®å‰ä¸€æ¬¡åªèƒ½åˆ†æä¸€å¼µåœ–ç‰‡ï¼Œå¦‚éœ€åˆ†æå¤šå¼µï¼Œè«‹åˆ†åˆ¥ä¸Šå‚³
        4. **åœ–ç‰‡æ ¼å¼**ï¼šæ”¯æŒå¸¸è¦‹åœ–ç‰‡æ ¼å¼ï¼ˆjpg, png, gif, webp, bmpï¼‰
        5. **API åˆ‡æ›**ï¼šç³»çµ±æœƒè‡ªå‹•é¸æ“‡å¯ç”¨çš„ API æä¾›å•†ï¼Œç„¡éœ€æ‰‹å‹•é…ç½®
        
        **âš ï¸ æ³¨æ„äº‹é …ï¼š**
        - åœ–ç‰‡å¤§å°å»ºè­°ä¸è¶…é 10MB
        - å¦‚æœä½¿ç”¨æœ¬åœ° Ollama LLaVAï¼Œé¦–æ¬¡ä½¿ç”¨å¯èƒ½éœ€è¦ä¸‹è¼‰æ¨¡å‹
        - ä¸åŒ API æä¾›å•†çš„å…è²»é¡åº¦ä¸åŒï¼Œå»ºè­°é…ç½®å¤šå€‹ä½œç‚ºå‚™æ´
        """
    )
